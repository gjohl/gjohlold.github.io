<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2023-08-30">
<meta name="description" content="Notes from Fast AI Practical Deep Learning for Coders Part 1">

<title>Gurpreet Johl - Fast AI Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Fast AI Notes</h1>
                  <div>
        <div class="description">
          Notes from Fast AI Practical Deep Learning for Coders Part 1
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 30, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#fast-ai-part-i" id="toc-fast-ai-part-i" class="nav-link active" data-scroll-target="#fast-ai-part-i">Fast AI Part I</a>
  <ul class="collapse">
  <li><a href="#introduction-to-image-classification-models" id="toc-introduction-to-image-classification-models" class="nav-link" data-scroll-target="#introduction-to-image-classification-models">1. Introduction to image classification models</a></li>
  <li><a href="#deployment" id="toc-deployment" class="nav-link" data-scroll-target="#deployment">2. Deployment</a></li>
  <li><a href="#how-does-a-neural-net-learn" id="toc-how-does-a-neural-net-learn" class="nav-link" data-scroll-target="#how-does-a-neural-net-learn">3. How does a neural net learn?</a></li>
  <li><a href="#natural-language-processing" id="toc-natural-language-processing" class="nav-link" data-scroll-target="#natural-language-processing">4. Natural language processing</a></li>
  <li><a href="#from-scratch-model" id="toc-from-scratch-model" class="nav-link" data-scroll-target="#from-scratch-model">5. From scratch model</a></li>
  <li><a href="#random-forests" id="toc-random-forests" class="nav-link" data-scroll-target="#random-forests">6. Random forests</a></li>
  <li><a href="#collaborative-filtering" id="toc-collaborative-filtering" class="nav-link" data-scroll-target="#collaborative-filtering">7. Collaborative filtering</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading">Further Reading</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="fast-ai-part-i" class="level1">
<h1>Fast AI Part I</h1>
<p>Notes from Fast AI Practical Deep Learning for Coders Part 1.</p>
<p>https://course.fast.ai/ https://github.com/fastai/fastbook/tree/master</p>
<section id="introduction-to-image-classification-models" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-image-classification-models">1. Introduction to image classification models</h2>
<blockquote class="blockquote">
<p>Homework task:</p>
<p>Train an image classifier https://github.com/gjohl/ml-practice/blob/master/ml-practice/notebooks/fastai/1_image_classifier.ipynb</p>
</blockquote>
<p>Ethics course https://ethics.fast.ai/</p>
<p>Research on education: Coloured cups - green, amber, red - Meta learning by Radek Osmulski Mathematician’s Lament by Paul Lockhart Making Learning Whole by David Perkins</p>
<p>Before deep learning, the approach to machine learning was to enlist many domain experts to handcraft features and feed this into a constrained linear model (e.g.&nbsp;ridge regression). This is time-consuming, expensive and requires many domain experts. Neural networks learn these features. Looking inside a CNN, for example, shows that these learned features match interpretable features that an expert might handcraft.</p>
<p>For image classifiers, you don’t need particularly large images as inputs. GPUs are so quick now that if you use large images, most of the time is spent on opening the file rather than computations. So often we resize images down to 400x400 pixels or smaller.</p>
<p>For most use cases, there are pre-trained models and sensible default values that we can use. In practice, most of the time is spent on the input layer and output layer. For most models the middle layers are identical.</p>
<p>Data blocks structure the input to learners. <code>DataBlock</code> class: - <code>blocks</code> determines the input and output type as a tuple. For multi-target classification this tuple can be arbitrary length. - <code>get_items</code> - function that returns a list of all the inputs - <code>splitter</code> - how to split the training/validation set - <code>get_y</code> - function that returns the label of a given input image - <code>item_tfms</code> - what transforms to apply to the inputs before training, e.g.&nbsp;resize - <code>dataloaders</code> - method that parallelises loading the data.</p>
<p>A learner combines the model (e.g.&nbsp;resnet or something from timm library) and the data to run that model on (the dataloaders from the DataBlock). - <code>fine_tune</code> method starts with a pretrained model weights rather than randomised weights, and only needs to learn the differences between your data and the original model.</p>
<p>Other image problems that can utilise deep learning - Image classification - Image segmentation</p>
<p>Other problem types use the same process, just with different DataBlock <code>blocks</code> types and the rest is the same. For example, tabular data, collaborative filtering.</p>
<p>RISE is a jupyter notebook extensions to turn notebooks into slides. Jeremy uses notebooks for: source code, book, blogging, CI/CD.</p>
<p>Traditional computer programs are essentially:</p>
<pre><code>inputs ---&gt; program ---&gt; results</code></pre>
<p>Deep learning models are:</p>
<pre><code>inputs ---&gt; model ---&gt; results ---&gt; loss
            ^                         |
weights ----|                         |
 ^                                    |
 |--------------(update)--------------|</code></pre>
</section>
<section id="deployment" class="level2">
<h2 class="anchored" data-anchor-id="deployment">2. Deployment</h2>
<blockquote class="blockquote">
<p>Homework task:</p>
<p>Deploy a model to Huggingface Spaces https://huggingface.co/spaces/GurpreetJohl/binary_image_classifier_vw_rr</p>
<p>Deploy a model to a Github Pages website https://github.com/gjohl/vw_classifier</p>
</blockquote>
<p>It can be useful to train a model on the data BEFORE you clean it - Counterintuitive! - The confusion matrix output of the learner gives you a good intuition about which classifications are hard - <code>plot_top_losses</code> shows which examples were hardest for the model to classify. This can find (1) when the model is correct but not confident, and (2) when the model was confident but incorrect - <code>ImageClassifierCleaner</code> shows the examples in the training and validation set ordered by loss, so we can choose to keep, reclassify or remove them</p>
<p>For image resizing, random resize crop can often be more effective. - Squishing can result in weird, unrealistic images - Padding or mirroing can add false information that the model will erroneously learn - Random crops give different sections of the image which acts as a form of data augmentation. - <code>aug_transforms</code> can be use for more sophisticated data augmentation like warping and recoloring images.</p>
<p>A website for quizzes based on the book: www.aiquizzes.com</p>
<p>Hugging face spaces hosts models with a choice of pre-canned interfaces (Gradio in the example in the lecture) to quickly deploy a model to the public. Streamlit is an alternative to Gradio that is more flexible. https://huggingface.co/spaces</p>
<p><strong>Saving a model</strong> Once you are happy with the model you’ve trained, you can pickle the learner object and save it.</p>
<pre><code>learn.export('model.pkl')</code></pre>
<p>Then you can add the saved model to the hugging face space. To use the model to make predictions Any external functions you used to create the model will need to be instantiated too.</p>
<pre><code>learn = load_learner('model.pkl')
learn.predict(image)</code></pre>
<p>Gradio requires a dict of classes as keys and probabilities (as floats not tensors) as the values. To go from the Gradio prototype to a production app, you can view the Gradio API from the huggingface space which will show you the API. The API exposes an endpoint which you can then hit from your own frontend app.</p>
<p>Github pages is a free and simple way to host a public website. See this repo as an example of a minimal example html website which issues GET requests to the Gradio API https://github.com/fastai/tinypets</p>
<p>To convert a notebook to a python script, you can add <code>#|export</code> to the top of any cells to include in the script, then use:</p>
<pre><code>from nbdev.export import notebook2script
notebook2script('name_of_output_file.py')</code></pre>
<p>Use <code>#|default_exp app</code> in the first cell of the notebook to set the default name of the exported python file.</p>
<p>How to choose the number of epochs to train for? Whenever it is “good enough” for your use case. If you need to train for longer, you may need to use data augmentation to prevent overfitting. Keep an eye on the validation error to check overfitting.</p>
</section>
<section id="how-does-a-neural-net-learn" class="level2">
<h2 class="anchored" data-anchor-id="how-does-a-neural-net-learn">3. How does a neural net learn?</h2>
<blockquote class="blockquote">
<p>Homework task: Recreate the spreadsheet to train a linear model and a neural network from scratch https://docs.google.com/spreadsheets/d/1hma4bTEFuiS483djqE5dPoLlbsSQOTioqMzsesZGUGI/edit?usp=sharing</p>
</blockquote>
<p>Options for cloud environments: Kaggle, Colab, Paperspace</p>
<p>Comparison of performance vs training time for different image models: https://www.kaggle.com/code/jhoward/which-image-models-are-best/ Resnet and convnext are generally good to start with. The best practice is to start with a “good enough” model with a quick training time, so you can iterate quickly. Then as you get further on with your research and need a better model, you can move to a slower, more accurate model. The criteria we generally care about are: 1. How fast are they 2. How much memory do they use 3. How accurate are they</p>
<p>A learner object contains the pre-processing steps and the model itself.</p>
<p><strong>Fit a quadratic function</strong> How do we fit a function to data? An ML model is just a function fitted to data. Deep learning is just fitting an infinitely flexible model to data. In <a href="https://www.kaggle.com/code/gurpreetjohl/how-does-a-neural-net-really-work">this notebook</a> there is an interactive cell to fit a quadratic function to some noisy data: <code>y = ax^2 +bx + c</code> We can vary a, b and c to get a better fit by eye. We can make this more rigorous by defining a loss function to quantify how good the fit is. In this case, use the mean absolute error <code>mae = mean(abs(actual - preds))</code> We can then use stochastic gradient descent to autome the tweaking of a, b and c to minimise the loss.</p>
<p>We can store the parameters as a tensor, then pytorch will calculate gradients of the loss function based on that tensor.</p>
<pre><code>abc = abc = torch.tensor([1.1,1.1,1.1]) 
abc.requires_grad_()  # Modifies abc in place so that it will include gradient calculations on anything which uses abc downstream
loss = quad_mae(abc)  # loss uses abc so we will get the gradient of loss too
loss.backward()  # Back-propagate the gradients
abc.grad  # Returns a tensor of the loss gradients</code></pre>
<p>We can then take a “small step” in the direction that will decrease the gradient. The size of the step should be proportional to the size of the gradient. We define a learning rate hyperparameter to determine how much to scale the gradients by.</p>
<pre><code>learning_rate = 0.01
abc -= abc.grad * learning_rate
loss = quad_mae(abc)  # The loss should now be smaller</code></pre>
<p>We can repeat this process to take multiple steps to minimise the gradient.</p>
<pre><code>for step in range(10):
    loss = quad_mae(abc)
    loss.backward()
    with torch.no_grad():
        abc -= abc.grad * learning_rate
    print(f'step={step}; loss={loss:.2f}')</code></pre>
<p>The learning rate should decrease as we get closer to the minimum to ensure we don’t overshoot the minimum and increase the loss. A learning rate schedule can be specified to do this.</p>
<p><strong>Fit a deep learning model</strong> For deep learning, the premise is the same but instead of quadratic functions, we fit ReLUs and other non-linear functions. <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">Universal approximation theorem</a> states that this is infinitely expressive if enough ReLUs (or other non-linear units) are combined. This means we can learn any computable function.</p>
<p>A ReLU is essentially a linear function with the negative values clipped to 0</p>
<pre><code>def relu(m,c,x):
    y = m * x + c
    return np.clip(y, 0.)</code></pre>
<p>This is all that deep learning is! All we need is: 1. A model - a bunch of ReLUs combined will be flexible 2. A loss function - mean absolute error between the actual data values and the values predicted by the model 3. An optimiser - stochastic gradient descent can start from random weights to incrementally improve the loss until we get a “good enough” fit</p>
<p>We just need enough time and data. There are a few hacks to decrease the time and data required: - Data augmentation - Running on GPUs to parallelise matrix multiplications - Convolutions to skip over values to reduce the number of matrix multiplications required - Transfer learning - initialise with parameters from another pre-trained model instead of random weights.</p>
<p><a href="https://docs.google.com/spreadsheets/d/1hma4bTEFuiS483djqE5dPoLlbsSQOTioqMzsesZGUGI/edit?usp=sharing">This spreadsheet</a> is a worked example of manually training a multivariate linear model, then extending that to a neural network summing two ReLUs.</p>
</section>
<section id="natural-language-processing" class="level2">
<h2 class="anchored" data-anchor-id="natural-language-processing">4. Natural language processing</h2>
<blockquote class="blockquote">
<p>Homework task:</p>
<p>Kaggle NLP pattern similarity notebook https://www.kaggle.com/code/gurpreetjohl/getting-started-with-nlp-for-absolute-beginners/edit</p>
</blockquote>
<p>NLP applications: categorising documents, translation, text generation.</p>
<p>Using <a href="https://huggingface.co/docs/transformers/index">Huggingface transformers</a> library for this lesson. It is now incorporated into the fastai library.</p>
<p>ULMFit is an algorithm which uses fine-tuning, in this example to train a positve/negative sentiment classifier in 3 steps: 1. Train an RNN on wikipedia to predict the next word. No labels required. 2. Fine-tune this for IMDb reviews to predict the next word of a movie review. Still no labels required. 3. Fine-tune this to classify the sentiment.</p>
<p>Transformers have overtaken ULMFit as the state-of-the-art.</p>
<p>Looking “inside” a CNN, the first layer contains elementary detectors like edge detectors, blob detectors, gradient detectors etc. These get combined in non-linear ways to make increasingly complex detectors. Layer 2 might combine vertical and horizontal edge detectors into a corner detector. By the later layers, it is detecting rich features like lizard eyes, dog faces etc. See: https://arxiv.org/abs/1311.2901</p>
<p>For the fine-tuning process, the earlier layers are unlikely to need changing because they are more general. So we only need to fine-tune (AKA re-train) the later layers.</p>
<p><strong>Kaggle competition walkthrough</strong></p>
<p>https://www.kaggle.com/code/gurpreetjohl/getting-started-with-nlp-for-absolute-beginners/edit</p>
<p>Reshape the input to fit a standard NLP task - We want to learn the similarity between two fields and are provided with similarity scores. - We concat the fields of interest (with identifiers in between). The identifiers themselves are not important, they just need to be consistent. - The NLP model is then a supervised regression task to predict the score given the concatendated string.</p>
<p><code>df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor</code></p>
<p><strong>Tokenization:</strong> Split the text into tokens (words). Tokens are, broadly speaking, words. There are some caveats to that, as some languages like Chinese don’t fit nicely into that model. We don’t want the vocabulary to be too big. In practice, we tokenize into subwords.</p>
<p><strong>Numericalization:</strong> Map each unique token to a number. One-hot encoding.</p>
<p>The choice of tokenization and numericalization depends on the model you use. Whoever trained the model chose a convention for tokenizing. We need to be consistent with that if we want the model to work correctly.</p>
<p><strong>Models:</strong> The Huggingface model hub contains thousands of pretrained models https://huggingface.co/models For NLP tasks, it is useful to choose a model that was trained on a similar corpus, so you can search the model hub. In this case, we search for “patent”.</p>
<p>Some models are general purpose, e.g.&nbsp;deberta-v3 used in the lesson.</p>
<p>ULMFit handles large documents better as it can split up the document. Transformer approaches require loading the whole document into GPU memory, so struggle for larger documents.</p>
<p><strong>Overfitting:</strong> If a model is too simple (i.e.&nbsp;not flexible enough) then it cannot fit the data and be biased. Underfitting.</p>
<p>If the model fits the data points too closely, it is overfitting.</p>
<p>A good validation set, and monitoring validation error rather than training error as a metric, is key to avoiding overfitting. https://www.fast.ai/posts/2017-11-13-validation-sets.html</p>
<p>Often people will default to using a random train/test split (this is what scikit-learn uses). This is a BAD idea very often. For time-series data, it’s easier to infer gaps than it is to predict a block in the future. The latter is the more common task but a random split simulates the former, giving unrealistically good performance. For image data, there may be people, boats, etc that are in the training set but not the test set. By failing to have new people in the validation set, the model can learn things about specific people/boats that it can’t rely on in practice.</p>
<p><strong>Metrics vs loss functions:</strong> Metrics are things that are human-understandable. Loss functions should be smooth and differentiable to aid in training.</p>
<p>These can sometimes be the same thing, but not in general. For example, accuracy is a good metric in image classification. We could tweak the weights in such a way that it improves the model slightly, but not so much that it now correctly classifies a previously incorrect image. This means the metric function is bumpy, therefore a bad loss function. https://www.fast.ai/posts/2019-09-24-metrics.html</p>
<p>AI can be particularly dangerous at confirming systematic biases, because it is so good at optimising metrics, so it will conform to any biases present in the training data. MAking decisions based on the model then reinforces those biases. - Goodhart’s law applies: If a metric becomes a target it’s no longer a good metric</p>
<p><strong>Correlations</strong> The best way to understand a metric is not to look at the mathematical formular, but to plot some data for which the metric is high, medium and low, then see what that tells you.</p>
<p>After that, look at the equation to see if your intuition matches the logic.</p>
<p><strong>Choosing a learning rate</strong> Fast AI has a function to find a good starting point. Otherwise, pick a small value and keep doubling it until it falls apart.</p>
</section>
<section id="from-scratch-model" class="level2">
<h2 class="anchored" data-anchor-id="from-scratch-model">5. From scratch model</h2>
<blockquote class="blockquote">
<p>Homework task: Recreate the Jupyter notebook to train a linear model and a neural network from scratch</p>
<p>Then use the fast AI library to recreate the same model in less code</p>
<p>Read the numpy broadcasting rules</p>
<p>Read through Titanic notebooks</p>
</blockquote>
<p>Train a linear model from scratch in Python using on the Titanic dataset. Then train a neural network from scratch in a similar way. This is an extension of the spreadsheet approach to make a neural network from scratch in lesson 3.</p>
<p><strong>Imputing missing values</strong> Never throw away data. An easy way of imputing missing values is to fill them with the mode. This is good enough for a first pass at creating a model.</p>
<p><strong>Scaling values</strong> Numeric values that can grow exponentially like prices or population sizes often have long-tailed distributions. An easy way to scale is to take log(x+1). The <code>+1</code> is just to avoid taking log of 0.</p>
<p><strong>Categorical variables</strong> One-hot encode any categorical variables. We should include an “other” category for each in case the validation or test set contains a category we didn’t encounter in the training set. If there are categories with ony a small number of observations we can group them into an “other” category too.</p>
<p><strong>Broadcasting</strong> Broadcasting arrays together avoids boilerplate code to make dimensions match. https://numpy.org/doc/stable/user/basics.broadcasting.html https://tryapl.org/</p>
<p><strong>Sigmoid final layer</strong> For a binary classification model, the outputs should be between 0 and 1. If you train a linear model, it might result in negative values or values &gt;1. This means we can improve the loss by just clipping to ensure they stay between 0 and 1. This is the idea behind the sigmoid function for output layers: smaller values will tend to 0 and larger values will tend to 1. In general, for any binary classification model, we should always have a sigmoid as the final layer. If the model isn’t training well, it’s worth checking that the final activation function is a sigmoid.</p>
<p>Function: <code>y = 1 / (1+e^-x))</code></p>
<p><strong>Focus on input and output layers</strong> In general, the middle layers of a neural network are similar between different problems. The input layer will depend on the data for our specific problem. The output will depend on the target for our specific problem. So we spend most of our time thinking about the correct input and output layers, and the hidden layers are less important.</p>
<p><strong>Using a framework</strong> When creating the models from scratch, there was a lot of boilerplate code to: - Impute missing values using the “obvious” method (fill with mode) - Normalise continuous variables to be between 0 and 1 - One hot encode categorical variables - Repeat all of these steps in the same order for the test set</p>
<p>The benefits of using a framework like fastai: - Less boilerplate, so the obvious things are done automatically unless you say otherwise - Repeating all of the feature engineering steps on the output is trivial with DataLoaders</p>
<p><strong>Ensemble</strong> Creating independent models and taking the mean of their predictions improves the accuracy. There are a few different approaches to ensembling a categorical variable: 1. Take the mean of the predictions (binary 0 or 1) 2. Take the mean of the probabilities (continuous between 0 and 1) then threshold the result 3. Take the mode of the predictions (binary 0 or 1)</p>
<p>In general the mean approaches work better but there’s no rule as to why, so try all of them.</p>
</section>
<section id="random-forests" class="level2">
<h2 class="anchored" data-anchor-id="random-forests">6. Random forests</h2>
<p>It’s worth starting with a random forest as a baseline model because “it’s very hard to screw up”. Decision trees only consider the ordering of data, so are not sensitive to outliers, skewed distributions, dummy variables etc.</p>
<p>A random forest is an ensemble of trees. A tree is an ensemble of binary splits. <code>binary split -&gt; tree -&gt; forest</code></p>
<p><strong>Binary split</strong> Pick a column of the data set and split the rows into two groups. Predict the outcome based just on that. For example, in the titanic dataset, pick the Sex column. This splits into male vs female. If we predict that all female passengers survived and all male passengers died, that’s a reasonably accurate prediction.</p>
<p>A model which iterates through the variables and finds the best binary split is called a “OneR” or one rule model. This was actually the state-of-the-art in the 90s and performs reasonably well across a lot of problems.</p>
<p><strong>Decision tree</strong> This extends the “OneR” idea to two or more splits. E.g. if we first split by sex, then find the next best variable to split on to create a two layer tree.</p>
<p>Leaf nodes are the number of terminating nodes in the tree. OneR creates 2 leaf nodes. If we split one side again, we’ll have 3 leaf nodes. If we split the other side, to create a balanced two layer tree, we’ll have 4 leaf nodes.</p>
<p>Gini is another measure of inequality, similar to the score used in the notebook to quantify how good a split was. Intuitively, this measures the likelihood that if you picked two samples from a group, how likely is it they’d be the same every time. If the group is all the same, the probability is 1. If every item is different, the probability is 0.</p>
<p><strong>Random forest</strong> The idea behind bagging is that if we have many unbiased, uncorrelated models, we can average their predictions to get an aggregate model that is better than any of them. Each individual model will overfit, so either be too high or too low for a given point, a positive or negative error term respectively. By combining multiple uncorrelated models, the error will average to 0.</p>
<p>An easy way to get many uncorrelated models is to only use a random subset of the data each time. Then build a decision tree for each subset. This is the idea behind random forests.</p>
<p>The error decreases with the number of tree, with diminishing returns. Jeremy’s rule of thumb: improvements level off after about 30 and he doesn’t often use &gt;100.</p>
<p><strong>Feature importance</strong> A nice side effect of using decision trees is that we get feature importance plots for free.</p>
<p>The idea is for each split of a decision tree, we can track the column used to split and the amount that the gini decreased by. If we loop through the tree and accumulate the “gini reduction” for each column, we have a metric of how important that column was in splitting the dataset.</p>
<p>This makes random forests a useful first model when tackling a new big dataset, as it can give an insight into how useful each column is.</p>
<p>A comment on explainability, regarding feature importance compared to SHAP, LIME etc. These explain the <em>model</em>, so to be useful the model needs to be accurate. If you use feature importance from a bad model then the columns it claims are important might not actually be. So the usefulness of explainability techniques boils down to what models can they explain and how accurate are those models.</p>
<p><strong>Out-of-bag error</strong> For each tree, we trained on a subset of the rows. We can then see how each one performed on the held out data; this is the out-of-bag error per tree. We can average this over all of the trees to get an overall OOB error for the forest.</p>
<p><strong>Partial dependence plots</strong> These are not specific to random forests and can be applied to any ML model including deep neural networks.</p>
<p>If we want to know how an independent variable affects the dependent variable, a naive approach would be to just plot them. But this could include a confounding variable. For example, the price of bulldozers increases over time, but driven by the presence of air conditioning which also increased over time.</p>
<p>A partial dependence plot takes each row in turn and sets the column(s) of interest to the first value, say, year=1950. Then we predict the target variable using our model. Then repeat this for year=1951, 1952, etc. We can then average the target variable per year to get a view of how it depends on the independent variable, all else being equal.</p>
<p><strong>Gradient boosting forests</strong> We make multiple trees, but instead of fitting all to different data subsets, we fit to residuals. So we fit a very small tree (OneR even) to the data to get a first prediction. Then we calculate the error term. Then we fit another tree to predict the error term. Then calculate the second order error term. Then fit a tree to this, etc.</p>
<p>Then our prediction is the SUM of these trees (rather than the average like with a random forest). This is “boosting”; calculating an error term then fitting another model to it. Contrast this with “bagging” which was when we calculate multiple models to different subsets of data and average them.</p>
<p><strong>Kaggle iterations</strong> The focus should be: 1. Create an effective validation set 2. Iterate quickly to find changes which improve the validation set</p>
<p>Train a simple model straight away, get a result and submit it. You can iterate and improve later.</p>
<p>Rules of thumb on model selection by problem type: - For computer vision use CNNs, fine-tune a pre-trained model. See comparison of pre-trained models <a href="https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning">here</a> - If unsure which model to choose, start with (small) convnext. - Different models can have big differences in accuracy so try a few small models from different families. - Once you are happy with the model, try a size up in that family. - For tabular data, random forests will give a reasonably good results. - GBMs will give a better result eventually, but with more effort required to get a good model. - Worth running a hyperparameter grid search for GBM because it’s fiddly.</p>
<p>Rules of thumb on hardware: - You generally want ~8 physical CPUs per GPU - If model training is CPU bound, it can help to resize images to be smaller. The file I/O on the CPU may be taking too long. - If model training is CPU bound and GPU usage is low, you might as well go up to a “better” (i.e.&nbsp;bigger) model with no increase of overall execution time.</p>
<p>Data augmentation, in particular test-time augmentation (TTA), can improve results.</p>
<p>Resizing images to a square is a good, easy compromise to accomodate many different iamge sizes , orientations and aspect ratios. A more involved approach that may improve results is to batch images together and resize them to the median rectangle size.</p>
</section>
<section id="collaborative-filtering" class="level2">
<h2 class="anchored" data-anchor-id="collaborative-filtering">7. Collaborative filtering</h2>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li>Bagging predictors https://link.springer.com/article/10.1007/BF00058655</li>
<li>Statistical Modeling: The Two Cultures https://www.semanticscholar.org/paper/Statistical-Modeling%3A-The-Two-Cultures-(with-and-a-Breiman/e5df6bc6da5653ad98e754b08f63326c2e52b372</li>
<li>Comparison of vision models https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning</li>
<li></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>